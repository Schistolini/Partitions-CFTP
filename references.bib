@article{propp1997coupling,
  title={Coupling from the past: A user's guide.},
  author={Propp, James and Wilson, David},
  journal={Microsurveys in discrete probability},
  volume={41},
  pages={181--192},
  year={1997},
  publisher={Citeseer}
}

@article{propp,
author = {Propp, James Gary and Wilson, David Bruce},
title = {Exact sampling with coupled Markov chains and applications to statistical mechanics},
journal = {Random Structures \& Algorithms},
volume = {9},
number = {1-2},
pages = {223-252},
doi = {https://doi.org/10.1002/(SICI)1098-2418(199608/09)9:1/2<223::AID-RSA14>3.0.CO;2-O},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-2418%28199608/09%299%3A1/2%3C223%3A%3AAID-RSA14%3E3.0.CO%3B2-O},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291098-2418%28199608/09%299%3A1/2%3C223%3A%3AAID-RSA14%3E3.0.CO%3B2-O},
abstract = {Abstract For many applications it is useful to sample from a finite set of objects in accordance with some particular distribution. One approach is to run an ergodic (i.e., irreducible aperiodic) Markov chain whose stationary distribution is the desired distribution on this set; after the Markov chain has run for M steps, with M sufficiently large, the distribution governing the state of the chain approximates the desired distribution. Unfortunately, it can be difficult to determine how large M needs to be. We describe a simple variant of this method that determines on its own when to stop and that outputs samples in exact accordance with the desired distribution. The method uses couplings which have also played a role in other sampling schemes; however, rather than running the coupled chains from the present into the future, one runs from a distant point in the past up until the present, where the distance into the past that one needs to go is determined during the running of the algorithm itself. If the state space has a partial order that is preserved under the moves of the Markov chain, then the coupling is often particularly efficient. Using our approach, one can sample from the Gibbs distributions associated with various statistical mechanics models (including Ising, random-cluster, ice, and dimer) or choose uniformly at random from the elements of a finite distributive lattice. Â© 1996 John Wiley \& Sons, Inc.},
year = {1996}
}

@misc{Weisstein , title={Plane Partition}, url={https://mathworld.wolfram.com/PlanePartition.html}, journal={from Wolfram MathWorld}, publisher={Wolfram}, author={Weisstein , Eric W}} 